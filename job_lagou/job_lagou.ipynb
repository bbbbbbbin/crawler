{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib3\n",
    "import urllib\n",
    "from lxml import etree\n",
    "import json\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support import expected_conditions\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pandas as pd\n",
    "import sys\n",
    "import pickle\n",
    "requests.packages.urllib3.disable_warnings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_website(url):\n",
    "    proxy_support = urllib3.PoolManager()\n",
    "    headers = [\"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2227.1 Safari/537.36\", \n",
    "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2227.0 Safari/537.36\", \n",
    "    \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2227.0 Safari/537.36\", \n",
    "    \"Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2226.0 Safari/537.36\", \n",
    "    \"Mozilla/5.0 (Windows NT 6.4; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2225.0 Safari/537.36\", \n",
    "    \"Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2225.0 Safari/537.36\", \n",
    "    \"Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2224.3 Safari/537.36\", \n",
    "    \"Mozilla/5.0 (Windows NT 10.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/40.0.2214.93 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2062.124 Safari/537.36\", \n",
    "    \"Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2049.0 Safari/537.36\", \n",
    "    \"Mozilla/5.0 (Windows NT 4.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2049.0 Safari/537.36\", \n",
    "    \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.67 Safari/537.36\", \n",
    "    \"Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.67 Safari/537.36\", \n",
    "    \"Mozilla/5.0 (X11; OpenBSD i386) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.125 Safari/537.36\", \n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1944.0 Safari/537.36\", \n",
    "    \"Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.3319.102 Safari/537.36\", \n",
    "    \"Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.2309.372 Safari/537.36\", \n",
    "    \"Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.2117.157 Safari/537.36\", \n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/34.0.1866.237 Safari/537.36\", \n",
    "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/34.0.1847.137 Safari/4E423F\", \n",
    "    \"Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/34.0.1847.116 Safari/537.36 Mozilla/5.0 (iPad; U; CPU OS 3_2 like Mac OS X; en-us) AppleWebKit/531.21.10 (KHTML, like Gecko) Version/4.0.4 Mobile/7B334b Safari/531.21.10\",\n",
    "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/33.0.1750.517 Safari/537.36\", \n",
    "    \"Mozilla/5.0 (Windows NT 6.2; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1667.0 Safari/537.36\", \n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1664.3 Safari/537.36\", \n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1664.3 Safari/537.36\", \n",
    "    \"Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/31.0.1650.16 Safari/537.36\", \n",
    "    \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/31.0.1623.0 Safari/537.36\", \n",
    "    \"Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/30.0.1599.17 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/29.0.1547.62 Safari/537.36\", \n",
    "    \"Mozilla/5.0 (X11; CrOS i686 4319.74.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/29.0.1547.57 Safari/537.36\", \n",
    "    \"Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/29.0.1547.2 Safari/537.36\", \n",
    "    \"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/28.0.1468.0 Safari/537.36\", \n",
    "    \"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/28.0.1467.0 Safari/537.36\", \n",
    "    \"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/28.0.1464.0 Safari/537.36\", \n",
    "    \"Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1500.55 Safari/537.36\", \n",
    "    \"Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.93 Safari/537.36\", \n",
    "    \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.93 Safari/537.36\", \n",
    "    \"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.93 Safari/537.36\", \n",
    "    \"Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.93 Safari/537.36\", \n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.93 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.93 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.90 Safari/537.36\", \n",
    "    \"Mozilla/5.0 (X11; NetBSD) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.116 Safari/537.36\", \n",
    "    \"Mozilla/5.0 (X11; CrOS i686 3912.101.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.116 Safari/537.36\", \n",
    "    \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.17 (KHTML, like Gecko) Chrome/24.0.1312.60 Safari/537.17\", \n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_2) AppleWebKit/537.17 (KHTML, like Gecko) Chrome/24.0.1309.0 Safari/537.17\", \n",
    "    \"Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.15 (KHTML, like Gecko) Chrome/24.0.1295.0 Safari/537.15\", \n",
    "    \"Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.14 (KHTML, like Gecko) Chrome/24.0.1292.0 Safari/537.14\"]\n",
    "    random_header = random.choice(headers)\n",
    "    headers = {\"User-Agent\":random_header}\n",
    "    req = proxy_support.request(method='Get', url=url, headers=headers)\n",
    "    if req.status != 200:\n",
    "        print('错误连接代码：{}'.format(req.status))\n",
    "        # ime.sleep(600)\n",
    "        return None\n",
    "        # return get_website(url)\n",
    "    return req.data.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.lagou.com/wn/jobs?kd={0}&city={1}&pn=1'.format(urllib.parse.quote('数据分析'),urllib.parse.quote('广州'))\n",
    "options = webdriver.ChromeOptions()\n",
    "# options.add_argument(\"headless\")\n",
    "options.add_experimental_option(\"excludeSwitches\", ['enable-automation','enable-logging'])\n",
    "options.add_argument('-ignore-certificate-errors')\n",
    "options.add_argument('-ignore -ssl-errors')\n",
    "# options.add_argument(\"headless\")\n",
    "browser = webdriver.Chrome('../chromedriver.exe',options=options)\n",
    "browser.maximize_window()\n",
    "\n",
    "browser.get(url)\n",
    "# page = browser.page_source\n",
    "html = browser.find_element(By.ID, 'jobList')\n",
    "html = html.get_attribute('innerHTML')\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "lists_top = soup(class_ = re.compile('^item-top'))\n",
    "lists_bottom = soup(class_ = re.compile('^item-bom'))\n",
    "p = soup(class_ = re.compile('^p-top'))\n",
    "classname = re.compile(r'class=\"(?P<name>.*?)\"').search(str(p[0])).group('name')\n",
    "mouse = browser.find_element(By.XPATH, '//*[@id=\"jobList\"]/div[1]/div[1]/div[1]/div[1]/div[1]/a')\n",
    "ActionChains(browser).move_to_element(mouse).perform()\n",
    "f = soup(class_ = re.compile('^modal_title_wrap'))\n",
    "# 获取页数\n",
    "pages = len(soup(class_ = re.compile('^lg-pagination-item')))\n",
    "# time.sleep(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"job_detail__2F5cP job-cur-detail\" style=\"top: 0px; right: 0px; visibility: visible;\"><div class=\"modal_title_wrap__20Dfa\"><div class=\"modal_title__3KO_X\"><p class=\"modal_title_text__1gawS\"><span>数据分析师</span><span class=\"modal_moeny__3A-bv\">12k-18k</span></p><p class=\"modal_title_discription__1Hjik\"><span class=\"modal_split__3v-9v\">广州</span><span class=\"modal_split__3v-9v\">3-5年</span><span class=\"modal_split__3v-9v\">本科</span><span class=\"modal_split__3v-9v\">全职</span></p></div><div class=\"star_btn__g1qgZ\"><img alt=\"\" class=\"star__1H-lx\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAMAAABEpIrGAAABnlBMVEUAAAAA//8A//8A/6oAzJkA1aoAv58Axo4AzJkAuYsAv5UAxJ0AtpIAu5kAv48AvJQAv4wAtpIAtYoAuI8As44AtpIAuY0AtYwAuYsAtI8AtooAtY0At5AAuYwAtowAtIsAtY4AuI8At4wAtYsAto0AtooAtI4AtYwAto4As4sAtI0AtosAtIsAtooAtowAs40AtIsAtY0AtosAtI0AtYsAs4sAtIwAs4wAtIoAtYsAs4wAtYwAtYsAtIoAtIoAtYsAtIsAtIwAs4oAtIsAtYoAtYwAtIsAs4sAtIsAs4oAtIsAtYsAtIsAtIsAtIwAtIsAtIsAs4oAtIsAtIsAtIoAs4sAtIwAs4sAtIoAtIsAtIsAs4sAtIsAtIoAs4sAtIsAtIsAtIoAtIsAtIsAtIoAtIsAs4sAs4oAtIoAs4sAtIoAtIsAs4sAtIsAtIsAtIoAtIsAs4sAtIsAs4sAtIsAtIsAtIsAs4oAs4sAtIoAs4sAs4oAtIsAtIoAtIsAs4oAtIsAs4oAs4sAtIoAs4oAtIoAs4sAs4oAtIsAs4q4k65wAAAAiXRSTlMAAQIDBQYICQoLDA0ODxATFBUYGRscHR8hIiMmJygqLC0yNTc4Oz0+P0BBQkRGSUpLTE1OT1FSVFVWW11haW1ucHN2d3h8fYCCg4SGi4+Sk5aXmpydnp+lpq2wsrS1tri7vr/BwsXGx8nKy8zO0NPa3N7g4uTm5+jp6uvs7fDx8vT19vf5+/z9/l7b3Q8AAAGLSURBVDjLjVL1WwJBFHxgYmKh2NgiYhd2d4vdrYiteHiigqfMf62LxB2y3+f75c3czM7t7lsiRY07xZlY4tcEfmqRr+d+SpUlH18FXMMyWz2HVW6AJOUQZfEjrFhijRuhlyQ96zpexBKsvyBSRFJ597w/wBex0GPUBjS1eWLjlp0/EMAiWDl2pztTiDKuGHHbrH01CQGDxtizcOxi35+KaB328faCqAh7yq4fOsUeuZHGv9pUvNMFBvmGYdjI5MUof3beaqKuT8yqIsnqOUgWBpo9WIn+q0evwtPwC6td2I4P1+O24KoKEIOAoxSlnnwIwRCieSLqlIYGiPkyqnpButKQhWfFU8FD+B6c0MlYGzbDDbtolLFJjIUbpjAiYzto8aMqkx9YsCYzCMj2ddMBcFTrg4W4CemZEFkzHwOiEzgx/5AoD5KChmJcEzWdA8JQomZAAM7qSf2InKAh5g4Hl8Bjv4ax+H4HYN/HtTr0j9I34L43LjiHvgfg1SA/lLa1TDHQmIoOLf2vvgHOv21vVkje7AAAAABJRU5ErkJggg==\"/><span class=\"job_pick__1zTnk\">收藏</span></div><button class=\"lg-button lg-button-primary lg-button-large deliver_resume__1YJVF\" style=\"padding: 11px 25px;\" type=\"button\"><span>投简历</span></button></div><div class=\"job_discription__1qxwN\"><div class=\"job_title__rEk9y\">职位描述</div><div class=\"job_info__rB-X6 job_desr_max__N_INq\"><div>工作职责：\n",
       "<br/>1、负责APP相关数据分析，包括数据平台建设、人群画像和数据标签完善、日常数据分析和专题分析；\n",
       "<br/>2、验证产品上线数据及策略效果，评估策略可行性，通过数据寻找优化空间，挖掘增长点；\n",
       "<br/>3、定期对行业、自身产品及竞品等数据分析和评估，提出产品优化建议和运营建议。\n",
       "<br/>\n",
       "<br/>任职要求：\n",
       "<br/>1、本科及以上学历，数学、统计等相关专业优先,三年以上互联网数据分析、商业分析经验；\n",
       "<br/>2、扎实的数理统计理论基础，有推荐系统、人群分类、用户标签，用户增长等项目经验优先，有直播社交行业数据分析经验者优先；\n",
       "<br/>3、能熟练使用EXCEL进行数据处理，熟练掌握SQL，有spark/presto/hive使用经验者优先考虑；\n",
       "<br/>4、自我驱动力强，追求卓越，工作细致、具备较强的学习能力及业务理解能力。 </div></div><div class=\"job_title__rEk9y\">工作地点<div><div><span>APP扫码</span><span>聊一聊</span></div><canvas height=\"85\" style=\"height: 85px; width: 85px;\" width=\"85\"></canvas></div></div><div class=\"job_info__rB-X6\">广州-海珠区-映客</div></div></div>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lists_item = soup(class_ = re.compile('^item__'))\n",
    "# mouse1 = browser.find_element(By.CLASS_NAME, classname)\n",
    "mouse1 = browser.find_element(By.XPATH, '//*[@id=\"jobList\"]/div[1]/div[1]/div[1]/div[1]/div[1]/a')\n",
    "ActionChains(browser).move_to_element(mouse1).perform()\n",
    "h = browser.find_element(By.ID, 'jobList')\n",
    "h = h.get_attribute('innerHTML')\n",
    "s = BeautifulSoup(h, \"html.parser\")\n",
    "f = s(class_ = re.compile('^job_detail'))\n",
    "f[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span>数据分析师</span>, <span class=\"modal_moeny__3A-bv\">12k-18k</span>]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[0](class_ = re.compile('^modal_title_text'))[0].select('span')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"modal_split__3v-9v\">广州</span>,\n",
       " <span class=\"modal_split__3v-9v\">3-5年</span>,\n",
       " <span class=\"modal_split__3v-9v\">本科</span>,\n",
       " <span class=\"modal_split__3v-9v\">全职</span>]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[0](class_ = re.compile('^modal_title_discription'))[0].select('span')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div class=\"job_info__rB-X6 job_desr_max__N_INq\"><div>工作职责：\n",
       " <br/>1、负责APP相关数据分析，包括数据平台建设、人群画像和数据标签完善、日常数据分析和专题分析；\n",
       " <br/>2、验证产品上线数据及策略效果，评估策略可行性，通过数据寻找优化空间，挖掘增长点；\n",
       " <br/>3、定期对行业、自身产品及竞品等数据分析和评估，提出产品优化建议和运营建议。\n",
       " <br/>\n",
       " <br/>任职要求：\n",
       " <br/>1、本科及以上学历，数学、统计等相关专业优先,三年以上互联网数据分析、商业分析经验；\n",
       " <br/>2、扎实的数理统计理论基础，有推荐系统、人群分类、用户标签，用户增长等项目经验优先，有直播社交行业数据分析经验者优先；\n",
       " <br/>3、能熟练使用EXCEL进行数据处理，熟练掌握SQL，有spark/presto/hive使用经验者优先考虑；\n",
       " <br/>4、自我驱动力强，追求卓越，工作细致、具备较强的学习能力及业务理解能力。 </div></div>,\n",
       " <div class=\"job_info__rB-X6\">广州-海珠区-映客</div>]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[0](class_ = re.compile('^job_discription'))[0](class_ = re.compile('^job_info'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"item-top__1Z3Zo\"><div class=\"position__21iOS\"><div class=\"p-top__1F7CL\"><a>数据分析师[新港]</a><span>19:09发布</span></div><div class=\"p-bom__JlNur\"><span class=\"money__3Lkgq\">12k-18k</span>经验3-5年 / 本科</div></div><div class=\"company__2EsC8\"><div class=\"company-name__2-SjF\"><a>北京蜜莱坞网络科技有限公司</a></div><div class=\"industry__1HBkr\">MCN｜直播平台 / 上市公司 / 500-2000人</div></div><div class=\"com-logo__1QOwC\"><img alt=\"北京蜜莱坞网络科技有限公司\" src=\"https://www.lgstatic.com/thumbnail_120x120/i/image/M00/08/49/Cgp3O1bPycGAMj0hAAAgshBCvv4840.jpg\"/></div></div>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lists_top[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'新港'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = re.compile(r'\\[(?P<area>.*?)\\]')\n",
    "p.search(str(lists_top[0].select('a')[0])).group('area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"company-name__2-SjF\"><a>北京蜜莱坞网络科技有限公司</a></div>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lists_top[0](class_ = re.compile('^company-name'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"industry__1HBkr\">MCN｜直播平台 / 上市公司 / 500-2000人</div>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lists_top[0](class_ = re.compile('^industry'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span>社交平台</span>,\n",
       " <span>MCN｜直播平台</span>,\n",
       " <span>SQL</span>,\n",
       " <span>Spark</span>]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lists_bottom[0].select('div')[0].select('span')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"il__3lk85\">“团队实力强，发展前景好”</div>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lists_bottom[0].select('div')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "job,city = '数据分析','广州'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取页数\n",
    "url = 'https://www.lagou.com/wn/jobs?kd={0}&city={1}&pn=1'.format(urllib.parse.quote(job),urllib.parse.quote(city))\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "# options.add_argument(\"headless\")\n",
    "options.add_experimental_option(\"excludeSwitches\", ['enable-automation','enable-logging'])\n",
    "options.add_argument('-ignore-certificate-errors')\n",
    "options.add_argument('-ignore -ssl-errors')\n",
    "browser = webdriver.Chrome('../chromedriver.exe',options=options)\n",
    "# browser.maximize_window()\n",
    "cookies = pickle.load(open(\"cookies.pkl\", \"rb\"))\n",
    "browser.get(url)\n",
    "for cookie in cookies:\n",
    "    browser.add_cookie(cookie)\n",
    "html = browser.find_element(By.ID, 'jobList')\n",
    "html = html.get_attribute('innerHTML')\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "pages = len(soup(class_ = re.compile('^lg-pagination-item')))\n",
    "browser.quit()\n",
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = 1\n",
    "for i in range(pages):\n",
    "    num = len(jobs)\n",
    "    a = 1\n",
    "    p = re.compile(r'\\[(?P<area>.*?)\\]')\n",
    "    url = 'https://www.lagou.com/wn/jobs?kd={0}&city={1}&pn={2}'.format(urllib.parse.quote(job),urllib.parse.quote(city),i+1)\n",
    "\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_experimental_option(\"excludeSwitches\", ['enable-automation','enable-logging'])\n",
    "    options.add_argument('-ignore-certificate-errors')\n",
    "    options.add_argument('-ignore -ssl-errors')\n",
    "    browser = webdriver.Chrome('../chromedriver.exe',options=options)\n",
    "    browser.maximize_window()\n",
    "    cookies = pickle.load(open(\"cookies.pkl\", \"rb\"))\n",
    "    browser.get(url)\n",
    "    for cookie in cookies:\n",
    "        browser.add_cookie(cookie)\n",
    "    html = browser.find_element(By.ID, 'jobList')\n",
    "    html = html.get_attribute('innerHTML')\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    lists_top = soup(class_ = re.compile('^item-top'))\n",
    "    lists_bottom = soup(class_ = re.compile('^item-bom'))\n",
    "    time.sleep(2)\n",
    "    browser.execute_script(\"window.scrollTo(0,0)\")\n",
    "    for i,j in zip(lists_top,lists_bottom):\n",
    "        jobs[num] = {}\n",
    "        # jobs[num]['工作标题'] = i(re.compile('^p-top'))[0].select('a')[0].text\n",
    "        mouse1 = browser.find_element(By.XPATH, '//*[@id=\"jobList\"]/div[1]/div[{0}]/div[1]/div[1]/div[1]/a'.format(a))\n",
    "        ActionChains(browser).move_to_element(mouse1).perform()\n",
    "        time.sleep(0.5)\n",
    "        h = browser.find_element(By.ID, 'jobList')\n",
    "        h = h.get_attribute('innerHTML')\n",
    "        s = BeautifulSoup(h, \"html.parser\")\n",
    "        f = s(class_ = re.compile('^job_detail'))\n",
    "        if len(f) == 0:\n",
    "            continue\n",
    "        jobs[num]['工作标题'] = f[0](class_ = re.compile('^modal_title_text'))[0].select('span')[0].text\n",
    "        jobs[num]['薪资'] = f[0](class_ = re.compile('^modal_title_text'))[0].select('span')[1].text\n",
    "        jobs[num]['地区'] = f[0](class_ = re.compile('^modal_title_discription'))[0].select('span')[0].text\n",
    "        jobs[num]['年限'] = f[0](class_ = re.compile('^modal_title_discription'))[0].select('span')[1].text\n",
    "        jobs[num]['学历'] = f[0](class_ = re.compile('^modal_title_discription'))[0].select('span')[2].text\n",
    "        jobs[num]['职限'] = f[0](class_ = re.compile('^modal_title_discription'))[0].select('span')[3].text\n",
    "        jobs[num]['职位详情'] = f[0](class_ = re.compile('^job_discription'))[0](class_ = re.compile('^job_info'))[0].text\n",
    "        jobs[num]['具体地点'] = f[0](class_ = re.compile('^job_discription'))[0](class_ = re.compile('^job_info'))[1].text\n",
    "        jobs[num]['公司名字'] = i(class_ = re.compile('^company-name'))[0].text\n",
    "        if len(i(class_ = re.compile('^industry'))) == 0:\n",
    "            jobs[num]['公司情况'] = None\n",
    "        else:\n",
    "            jobs[num]['公司情况'] = i(class_ = re.compile('^industry'))[0].text\n",
    "        jobs[num]['职位标签'] = []\n",
    "        for k in j.select('div')[0].select('span'):\n",
    "            jobs[num]['职位标签'].append(k.text)\n",
    "        jobs[num]['公司标签'] = j.select('div')[1].text\n",
    "        jobs[num]['地区'] = p.search(str(lists_top[0].select('a')[0])).group('area')\n",
    "        browser.execute_script(\"window.scrollTo(0,{})\".format(a*80))\n",
    "        a += 1\n",
    "        num += 1\n",
    "    browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(jobs).T\n",
    "data.to_csv('data_{0}_{1}_{2}.csv'.format(city, job, page))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "可运行主要的代码，先运行此代码块初始化浏览器，然后运行下一个代码块获取页面信息，通过点击下一页获取下一页的信息\n",
    "'''\n",
    "url = 'https://www.lagou.com/wn/jobs?kd={0}&city={1}&pn=1'.format(urllib.parse.quote(job),urllib.parse.quote(city))\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_experimental_option(\"excludeSwitches\", ['enable-automation','enable-logging'])\n",
    "options.add_argument('-ignore-certificate-errors')\n",
    "options.add_argument('-ignore -ssl-errors')\n",
    "browser = webdriver.Chrome('../chromedriver.exe',options=options)\n",
    "browser.maximize_window()\n",
    "cookies = pickle.load(open(\"cookies.pkl\", \"rb\"))\n",
    "browser.get(url)\n",
    "for cookie in cookies:\n",
    "    browser.add_cookie(cookie)\n",
    "html = browser.find_element(By.ID, 'jobList')\n",
    "html = html.get_attribute('innerHTML')\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "pages = len(soup(class_ = re.compile('^lg-pagination-item')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = {}\n",
    "b = 1\n",
    "p = re.compile(r'\\[(?P<area>.*?)\\]')\n",
    "while(b <= pages):\n",
    "    num = len(jobs)\n",
    "    a = 1\n",
    "    html = browser.find_element(By.ID, 'jobList')\n",
    "    html = html.get_attribute('innerHTML')\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    lists_top = soup(class_ = re.compile('^item-top'))\n",
    "    lists_bottom = soup(class_ = re.compile('^item-bom'))\n",
    "    time.sleep(2)\n",
    "    browser.execute_script(\"window.scrollTo(0,0)\")\n",
    "    for i,j in zip(lists_top,lists_bottom):\n",
    "        jobs[num] = {}\n",
    "        # jobs[num]['工作标题'] = i(re.compile('^p-top'))[0].select('a')[0].text\n",
    "        try:\n",
    "            mouse1 = browser.find_element(By.XPATH, '//*[@id=\"jobList\"]/div[1]/div[{0}]/div[1]/div[1]/div[1]/a'.format(a))\n",
    "        except:\n",
    "            continue\n",
    "        ActionChains(browser).move_to_element(mouse1).perform()\n",
    "        time.sleep(0.5)\n",
    "        h = browser.find_element(By.ID, 'jobList')\n",
    "        h = h.get_attribute('innerHTML')\n",
    "        s = BeautifulSoup(h, \"html.parser\")\n",
    "        f = s(class_ = re.compile('^job_detail'))\n",
    "        if len(f) == 0:\n",
    "            continue\n",
    "        jobs[num]['工作标题'] = f[0](class_ = re.compile('^modal_title_text'))[0].select('span')[0].text\n",
    "        jobs[num]['薪资'] = f[0](class_ = re.compile('^modal_title_text'))[0].select('span')[1].text\n",
    "        jobs[num]['城市'] = f[0](class_ = re.compile('^modal_title_discription'))[0].select('span')[0].text\n",
    "        jobs[num]['地区'] = p.search(str(i.select('a')[0])).group('area')\n",
    "        jobs[num]['年限'] = f[0](class_ = re.compile('^modal_title_discription'))[0].select('span')[1].text\n",
    "        jobs[num]['学历'] = f[0](class_ = re.compile('^modal_title_discription'))[0].select('span')[2].text\n",
    "        jobs[num]['职限'] = f[0](class_ = re.compile('^modal_title_discription'))[0].select('span')[3].text\n",
    "        jobs[num]['职位详情'] = f[0](class_ = re.compile('^job_discription'))[0](class_ = re.compile('^job_info'))[0].text\n",
    "        jobs[num]['具体地点'] = f[0](class_ = re.compile('^job_discription'))[0](class_ = re.compile('^job_info'))[1].text\n",
    "        jobs[num]['公司名字'] = i(class_ = re.compile('^company-name'))[0].text\n",
    "        if len(i(class_ = re.compile('^industry'))) == 0:\n",
    "            jobs[num]['公司情况'] = None\n",
    "        else:\n",
    "            jobs[num]['公司情况'] = i(class_ = re.compile('^industry'))[0].text\n",
    "        jobs[num]['职位标签'] = []\n",
    "        for k in j.select('div')[0].select('span'):\n",
    "            jobs[num]['职位标签'].append(k.text)\n",
    "        jobs[num]['公司标签'] = j.select('div')[1].text\n",
    "        browser.execute_script(\"window.scrollTo(0,{})\".format(a*80))\n",
    "        a += 1\n",
    "        num += 1\n",
    "    # 点击下一页\n",
    "    try:\n",
    "        browser.find_element(By.CLASS_NAME, 'lg-pagination-next').click()\n",
    "    except:\n",
    "        continue\n",
    "    b+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(jobs).T\n",
    "data.to_csv('data_{0}_{1}.csv'.format(city, job))\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b09ec625f77bf4fd762565a912b97636504ad6ec901eb2d0f4cf5a7de23e1ee5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
